{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from pandas.tools.plotting import parallel_coordinates\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aafe34a9ada4c4bac079aab82dff84a355dab905"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../input/train.csv\")\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e99c6b64e6201c6a33b22b2146eafadf2ce45c2d"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "IDtest = test[\"PassengerId\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "916f18e207ba5c871d4312033ef27ca97aedbdea"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "868fa0abf39b8c1a094720bc9565fa4adfdb3526"
   },
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b510b62ffb798039e2b7ccf9c33d93e64a20b0ab"
   },
   "source": [
    "Clean data by dropping columns which we are not using for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "197b44e5b405e0209bdb2106fe89734fe4d319b0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.drop(['PassengerId','Ticket'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "07e00bdae0f047512d969d04f8894b8ba722db03"
   },
   "source": [
    "Check wether data have null values or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11aeed5802d4d538137841c8ab24c5ac5bb46cf6"
   },
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ba18a46e62a7dab8901d91a388f2d1c554d2dc2"
   },
   "source": [
    "Cleaning missing data\n",
    "\n",
    "In statistics, missing data, or missing values, occur when no data value is stored for the variable in an observation. Missing data are a common occurrence and can have a significant effect on the conclusions that can be drawn from the data. The goal of cleaning operations is to prevent problems caused by missing data that can arise when training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ea490ffd41fa7e51519b5e6f0daad5487e36a7a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Fill Embarked nan values of dataset set with 'S' most frequent value\n",
    "train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(\"C\")\n",
    "test[\"Embarked\"] = test[\"Embarked\"].fillna(\"C\")\n",
    "\n",
    "#complete missing fare with median\n",
    "train_data['Fare'].fillna(train_data['Fare'].median(), inplace = True)\n",
    "test['Fare'].fillna(test['Fare'].median(), inplace = True)\n",
    "\n",
    "## Assigning all the null values as \"N\"\n",
    "train_data.Cabin.fillna(\"N\", inplace=True)\n",
    "test.Cabin.fillna(\"N\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f224bfb516007c648e6130010ef18d907e7648a6"
   },
   "source": [
    "Check whether all missing data are filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a8c7fe1595dad7d7d4da91e740f6a73447f25b9"
   },
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d7e3c059957f8138ffbaa385df88b59909324d45"
   },
   "source": [
    "**Feature engineering** :  Name/Title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11a2bab680a15845fac3fab2286fa5c7cfd387a8"
   },
   "outputs": [],
   "source": [
    "train_data[\"Name\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5bdc17613d0135967e4e5156b671f038e6cdf052"
   },
   "outputs": [],
   "source": [
    "# Get Title from Name\n",
    "train_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in train_data[\"Name\"]]\n",
    "train_data[\"Title\"] = pd.Series(train_title)\n",
    "train_data[\"Title\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "261aedc2c16ab13420b734a7a8ceba640b23c0a2"
   },
   "outputs": [],
   "source": [
    "# Get Title from Name\n",
    "test_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in test[\"Name\"]]\n",
    "test[\"Title\"] = pd.Series(test_title)\n",
    "test[\"Title\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57b7506b8dc5e635b57e65e1c3e14d2e75a41159"
   },
   "outputs": [],
   "source": [
    "g = sns.countplot(x=\"Title\",data=train_data)\n",
    "g = plt.setp(g.get_xticklabels(), rotation=45) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c14bb35235f6de659ad9db9013a6d934214a98c9"
   },
   "outputs": [],
   "source": [
    "# Convert to categorical values Title \n",
    "train_data[\"Title\"] = train_data[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "train_data[\"Title\"] = train_data[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n",
    "train_data[\"Title\"] = train_data[\"Title\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "768624041dcf09b1345b9c2295673f942019faf4"
   },
   "outputs": [],
   "source": [
    "# Convert to categorical values Title \n",
    "test[\"Title\"] = test[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "test[\"Title\"] = test[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n",
    "test[\"Title\"] = test[\"Title\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8eaf806b7d030869790cec672e357e004f528a08"
   },
   "outputs": [],
   "source": [
    "g = sns.countplot(x=\"Title\",data=train_data)\n",
    "g = plt.setp(g.get_xticklabels(), rotation=45) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b2e1d1b035146f018efa3089be38d08a559d376f"
   },
   "outputs": [],
   "source": [
    "# group by Sex, Pclass, and Title \n",
    "grouped = train_data.groupby(['Sex','Pclass', 'Title'])  \n",
    "# view the median Age by the grouped features \n",
    "grouped.Age.median()\n",
    "# apply the grouped median value on the Age NaN\n",
    "train_data.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b29cf5977c3e474531f19b7c9b9655bb61cf1a9e"
   },
   "outputs": [],
   "source": [
    "# group by Sex, Pclass, and Title \n",
    "test_grouped = test.groupby(['Sex','Pclass', 'Title'])  \n",
    "# view the median Age by the grouped features \n",
    "test_grouped.Age.median()\n",
    "# apply the grouped median value on the Age NaN\n",
    "test.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a24f9d3fdd7320079a26dc4f37317b608e20dae"
   },
   "source": [
    "**Feature engineering** :  Family size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "efb525351ae73876779c128e1f5a74603c828fa3"
   },
   "outputs": [],
   "source": [
    "# Create a family size descriptor from SibSp and Parch\n",
    "train_data[\"Family_size\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1\n",
    "test[\"Family_size\"] = test[\"SibSp\"] + test[\"Parch\"] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d481e49b44f526ee277c7af0018af6713287888"
   },
   "outputs": [],
   "source": [
    "train_data['survived_dead'] = train_data['Survived'].apply(lambda x : 'Survived' if x == 1 else 'Dead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de6326afc66061c66869afe4c9077602716af9b9"
   },
   "outputs": [],
   "source": [
    "sns.clustermap(data = train_data.corr().abs(),annot=True, fmt = \".2f\", cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6995ac9d413f514b4e67bb6aedc821611044bb91"
   },
   "outputs": [],
   "source": [
    "sns.countplot('survived_dead', data = train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ce16d7fc817fe3b3579e9865cabf7f5f0a966db"
   },
   "outputs": [],
   "source": [
    "sns.countplot( train_data['Sex'],data = train_data, hue = 'survived_dead', palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1cf0cca6508de8406c7c7915eda21d26939e74d0"
   },
   "outputs": [],
   "source": [
    "sns.countplot( train_data['Pclass'],data = train_data, hue = 'survived_dead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60366192a0c503661630b5141095697ee6b2bf5d"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Pclass', y = 'Fare', data = train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3956eadbc958bae715f37083a17e0181046cdc0d"
   },
   "outputs": [],
   "source": [
    "sns.pointplot(x = 'Sex', y = 'Survived', hue = 'Pclass', data = train_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b2d155366f395a310997e7e059623c08b2946db"
   },
   "source": [
    "Fare - Passenger Fare\n",
    "Embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "885cdaf397f984986fb440a8d3e4cb8d03c3a243"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x  = 'Embarked', y = 'Fare', data = train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f6101b586fbe47d7c78ff81d0a75fba71a2fd86"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train_data, hue='Survived')\n",
    "g.map(sns.kdeplot, \"Age\",shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ce2f545d19c50f5c2493a0b32c17a350d68d074",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\",\n",
    "            col=\"Pclass\", kind = 'bar',data=train_data, palette = \"rainbow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "485b9601de26aa8c16a38652847d0689a1f3db7a"
   },
   "source": [
    "sibsp - Number of Siblings/Spouses Aboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de61ea610fc114d2a3a886a0a49f7647b5b224d6"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='SibSp', y='Survived',hue = 'Sex',data=train_data, kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3158855ffaa4a5389aad318a85e278a5db2e831e"
   },
   "source": [
    "parch - Number of Parents/Children Aboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b21ec96239e0bc5f39a23c06f9ff1a638275bc44"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='Parch', y='Survived',hue = 'Sex',data=train_data, kind='point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74d185b31c2b87c8fe90f9fabcff50344b11fb7a"
   },
   "outputs": [],
   "source": [
    "g= sns.FacetGrid(data = train_data, row = 'Sex', col = 'Pclass', hue = 'survived_dead')\n",
    "g.map(sns.kdeplot, 'Age', alpha = .75, shade = True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "639d9012876a4dc0fe7039b602eb26f306fef495"
   },
   "outputs": [],
   "source": [
    "categoricals = train_data.select_dtypes(exclude=[np.number])\n",
    "categoricals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03ea06fcc7e7be83585ef1f6617519eb35161d54"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "lbl = LabelEncoder() \n",
    "lbl.fit(list(train_data['Embarked'].values)) \n",
    "train_data['Embarked'] = lbl.transform(list(train_data['Embarked'].values))\n",
    "lbl.fit(list(test['Embarked'].values)) \n",
    "test['Embarked'] = lbl.transform(list(test['Embarked'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71bbc4c84814632857d8d823e56719d1522e5247"
   },
   "outputs": [],
   "source": [
    "def encode(x): return 1 if x == 'female' else 0\n",
    "train_data['enc_sex'] = train_data.Sex.apply(encode)\n",
    "test['enc_sex'] = test.Sex.apply(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7bee015d6733461d0b178bef3736e63b082cbf7f"
   },
   "outputs": [],
   "source": [
    "train_data[\"has_cabin\"] = [0 if i == 'N'else 1 for i in train_data.Cabin]\n",
    "test[\"has_cabin\"] = [0 if i == 'N'else 1 for i in test.Cabin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d75a5e331ee4b71bce35c12f6af4381b6f781992"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Outlier detection \n",
    "\n",
    "def detect_outliers(train_data,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(train_data[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(train_data[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = train_data[(train_data[col] < Q1 - outlier_step) | (train_data[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   \n",
    "\n",
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "Outliers_to_drop = detect_outliers(train_data,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ebaaeda1c9fd83baa4b64c495f849139f595251"
   },
   "outputs": [],
   "source": [
    "train_data.loc[Outliers_to_drop] # Show the outliers rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "260b6cddbbab57c3390e7509e87d4cd5c691ba71"
   },
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "train_data = train_data.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ccda432c5cb4b9946f34db0a57e852fb379b893e"
   },
   "outputs": [],
   "source": [
    "data = train_data.select_dtypes(include=[np.number]).interpolate().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "123c64d68e348d43b7e8a0035ae0f0c111aa68cf"
   },
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]\n",
    "\n",
    "X_train = data.drop(labels = [\"Survived\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "023ffb530304efa2719a907920003bf651bb72c3"
   },
   "outputs": [],
   "source": [
    "test = test.select_dtypes(include=[np.number]).interpolate().dropna()\n",
    "test = test[X_train.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea8f0d5478be0e348193be05651682f6117682fb"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "test = sc.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "810f43142e829a3dfa5967ba218bc914cb93aff5"
   },
   "outputs": [],
   "source": [
    "# Cross validate model with Kfold stratified cross val\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebb0b69f10daab3bcba1b52b800cd148983e5313"
   },
   "outputs": [],
   "source": [
    "#ExtraTrees \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ExtC = ExtraTreesClassifier()\n",
    "\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "ex_param_grid = {\"max_depth\":  [n for n in range(9, 14)],  \n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [n for n in range(4, 11)],\n",
    "              \"min_samples_leaf\": [n for n in range(2, 5)],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[n for n in range(10, 60, 10)],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsExtC.fit(X_train,y_train)\n",
    "\n",
    "ExtC_best = gsExtC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsExtC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7bd307d2e1b21aa699d52b238cadefbddb08f4bd"
   },
   "outputs": [],
   "source": [
    "# RFC Parameters tunning \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\":  [n for n in range(9, 14)],  \n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [n for n in range(4, 11)],\n",
    "              \"min_samples_leaf\": [n for n in range(2, 5)],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[n for n in range(10, 60, 10)],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 1, verbose = 1)\n",
    "\n",
    "gsRFC.fit(X_train,y_train)\n",
    "\n",
    "RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsRFC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a01fcf52428c805c6328a04f23e86a59966de4ba"
   },
   "outputs": [],
   "source": [
    "# Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DTC = DecisionTreeClassifier()\n",
    "\n",
    "adaDTC = AdaBoostClassifier(DTC, random_state=7)\n",
    "\n",
    "ada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n",
    "              \"n_estimators\" :[30],\n",
    "              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n",
    "\n",
    "gsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsadaDTC.fit(X_train,y_train)\n",
    "\n",
    "ada_best = gsadaDTC.best_estimator_\n",
    "\n",
    "gsadaDTC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27272d022a16b33eca12f1cce271d846144a8474"
   },
   "outputs": [],
   "source": [
    "### SVC classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "SVMC = SVC(probability=True)\n",
    "svc_param_grid = {'kernel': ['rbf'], \n",
    "                  'gamma': [ 0.001, 0.01, 0.1, 1],\n",
    "                  'C': [1, 10, 50, 100,200,300, 1000]}\n",
    "\n",
    "gsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsSVMC.fit(X_train,y_train)\n",
    "\n",
    "SVMC_best = gsSVMC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsSVMC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "916534bd08e357d299f01e315eaa5544583a7747"
   },
   "outputs": [],
   "source": [
    "# Gradient boosting tunning\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBC = GradientBoostingClassifier()\n",
    "gb_param_grid = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [n for n in range(10, 60, 10)],\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth':  [n for n in range(9, 14)],  \n",
    "              'min_samples_leaf': [n for n in range(2, 5)],\n",
    "              'max_features': [0.3, 0.1] \n",
    "              }\n",
    "\n",
    "gsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsGBC.fit(X_train,y_train)\n",
    "\n",
    "GBC_best = gsGBC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsGBC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b8261225a0a33282a276d3df629f09c7727debb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "votingC = VotingClassifier(estimators=[('rfc', RFC_best), ('extc', ExtC_best),('svm',SVMC_best),\n",
    "('gbc',GBC_best)], voting='soft', n_jobs=4)\n",
    "\n",
    "votingC = votingC.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a9fcdfca3375ab132d86418d0a00dd5fe648924"
   },
   "outputs": [],
   "source": [
    "test_Survived = pd.Series(votingC.predict(test), name=\"Survived\")\n",
    "\n",
    "Submission = pd.concat([IDtest,test_Survived],axis=1)\n",
    "Submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33dd53ddae789e2cdada5cd963bf135066e1a1cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "997ba4005802d72effffa25606413186feec43a3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
